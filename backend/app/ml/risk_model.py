# -*- coding: utf-8 -*-
"""Copy of updated_pred_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CASu-bbOi-Rlywz-MoEWhUWBsS27doxv
"""

import os
import logging
import sys
import pandas as pd
import numpy as np
import joblib
import kagglehub
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from flask import Flask, request, jsonify

def setup_logging():
    logging.basicConfig(stream=sys.stdout)
    #logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def load_data(data_path):
    try:
        path = kagglehub.dataset_download(data_path)
        logging.info(f"Path to dataset files: {path}")
        logging.info(f"Files in dataset: {os.listdir(path)}")
        df = pd.read_csv(os.path.join(path, "Loan.csv"))
        logging.info("Dataset loaded successfully.")
        return df
    except Exception as e:
        logging.error(f"Error loading dataset: {e}")
        return None

def preprocess_data(df):
    df = df.drop(columns=["ApplicationDate"], errors='ignore')
    df['Liquidity_Ratio'] = (df['SavingsAccountBalance'] + df['CheckingAccountBalance']) / df['LoanAmount']
    df['Relative_Ratio'] = df['MonthlyIncome'] / (df['LoanAmount'] / df['LoanDuration'])
    df["IncomePerDependent"] = df["AnnualIncome"] / (df["NumberOfDependents"] + 1)
    categories = ['EmploymentStatus', 'EducationLevel', 'MaritalStatus', 'NumberOfDependents',
                  'HomeOwnershipStatus', 'LoanPurpose', 'LoanApproved']
    #identified categorical variables based on domain knowledge
    df = df.drop(columns=categories, errors='ignore')
    #removing them as they didn't show significant prominence in determining risk score(analysed using box and violin plots)
    return df

def train_model(df):
    df=preprocess_data(df)
    X = df.drop(columns=['RiskScore'])
    y = df['RiskScore']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    model = RandomForestRegressor(random_state=42)
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    logging.info(f"Model Performance - MSE: {mse}, R2: {r2}")

    joblib.dump(model, "loan_risk_model.pkl")
    logging.info("Model saved successfully.")
    print("Model saved successfully.")
    return model

def load_model(model_pkl):
    if os.path.exists(model_pkl):
        return joblib.load(model_pkl)
    else:
        logging.error("Model file not found.")
        return None

def get_risk_score(model_pkl, input_data):
  try:
      model = joblib.load(model_pkl)
      prediction = model.predict(input_data)
      return prediction
  except Exception as e:
      logging.error(f"ERROR OCCURED: {e}")
      return None

def get_updated_dataset(raw_data,predictions):
  raw_data['Predicted_RiskScore'] = predictions  # Add a new column for predictions
  return raw_data

if __name__ == "__main__":
    setup_logging()
    sample_input = load_data("lorenzozoppelletto/financial-risk-for-loan-approval")
    model_pkl="loan_risk_model.pkl"

    if not os.path.exists(model_pkl):
      train_model(sample_input)
    #model=load_model(model_pkl)

    if sample_input is not None:
        sample_input1 = preprocess_data(sample_input)
        sample_input1 = sample_input1.drop(columns=['RiskScore'])

        predictions=get_risk_score(model_pkl, sample_input1)
        print(predictions)
        updated_dataset = get_updated_dataset(sample_input, predictions)
        print(updated_dataset.head())
    else:
        logging.error("Failed to load dataset.")





